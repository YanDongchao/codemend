{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Learn to Overfit One-Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../models/')\n",
    "import bimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import ast\n",
    "import astunparse\n",
    "import myast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import multiply as np_mult, exp, dot, outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MEMSIZE = 2\n",
    "code = \"f(x)\"\n",
    "node = ast.parse(code)\n",
    "myast_node = myast.MyAST(node=node)\n",
    "utter = 'blah'\n",
    "train_pairs = [(utter, myast_node)]\n",
    "\n",
    "def reset_model():\n",
    "    global model\n",
    "    \n",
    "    reload(bimodal);\n",
    "\n",
    "    model = bimodal.BiModal(\n",
    "        train_pairs = train_pairs,\n",
    "        size = 4,\n",
    "        min_count = None,\n",
    "        workers = 1,\n",
    "        iter_ = 100,\n",
    "        null_word=False,\n",
    "        sample = None,\n",
    "        additive = True,\n",
    "        memsize_k = MEMSIZE,\n",
    "        memsize_i = MEMSIZE,\n",
    "        alpha = 1,  # CAUTION!!!!!!!!!!!!\n",
    "        seed = 1,\n",
    "        train_on_init=False)\n",
    "\n",
    "    model.neg_labels = np.array([1, 0])\n",
    "\n",
    "reset_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([], [NODE_Name, FIELD_func], FIELD_id, f),\n",
       " ([f], [NODE_Name, FIELD_args], FIELD_id, x))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptree1 = ([], \n",
    "          [myast.SimpleAstNode(node_type=ast.Name),\n",
    "           myast.SimpleAstNode(field_name='func')],\n",
    "          myast.SimpleAstNode(field_name='id'),\n",
    "          myast.SimpleAstNode(content='f'))\n",
    "ptree2 = ([myast.SimpleAstNode(content='f')], \n",
    "          [myast.SimpleAstNode(node_type=ast.Name),\n",
    "           myast.SimpleAstNode(field_name='args')],\n",
    "          myast.SimpleAstNode(field_name='id'),\n",
    "          myast.SimpleAstNode(content='x'))\n",
    "next_ptree = ptree1\n",
    "ptree1, ptree2\n",
    "# terminals, ancestors, parent, children\n",
    "\n",
    "# Linearly separable. we want the model to learn to distinguish \n",
    "# these two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_weights(model, i_idxs, k_idxs, l_idxs, r_idxs):\n",
    "    assert len(i_idxs) == model.hmati.shape[0]\n",
    "    assert len(k_idxs) == model.hmatk.shape[0]\n",
    "    assert len(l_idxs) > 0\n",
    "    assert len(r_idxs) > 1\n",
    "\n",
    "    hmati = model.hmati  # memsize_i * vector_size\n",
    "    hmatk = model.hmatk  # memsize_k * vector_size\n",
    "    i_vecs = model.syn0i[i_idxs]  # memsize_i * vector_size\n",
    "    k_vecs = model.syn0k[k_idxs]  # memsize_k * vector_size\n",
    "    l_vecs = model.syn0l[l_idxs]  # arbitrary * vector_size\n",
    "    r_vecs = model.syn1r[r_idxs]  # num_candidates * vector_size\n",
    "    b = model.syn1b[r_idxs]  # 1 * num_candidates\n",
    "\n",
    "    c = np.multiply(i_vecs, hmati).sum(0) + \\\n",
    "            np.multiply(k_vecs, hmatk).sum(0)  # 1 * vector_size\n",
    "    l = l_vecs.mean(0)  # 1 * vector_size\n",
    "\n",
    "    if model.additive:\n",
    "        h = c + l  # 1 * vector_size\n",
    "    else:\n",
    "        h = np.multiply(c, l)\n",
    "\n",
    "    # weights: outputs of the output-layer nodes\n",
    "    weights = np.exp(np.dot(h, r_vecs.T) + b)  # 1 * num_candidates\n",
    "    #     for r_idx, w in zip(r_idxs, weights):\n",
    "    #         print w, r_idx\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_iklr(utter, ptree):\n",
    "    terminals, ancestors, parent, children = ptree\n",
    "    l_idxs = bimodal.get_l_idxs(model, utter)\n",
    "    # print 'l_idxs', l_idxs, utter\n",
    "\n",
    "    k_idxs = [model.vocab_k[x] for x in reversed(terminals)]\n",
    "    k_idxs += [0] * (model.memsize_k - len(k_idxs))  # padding\n",
    "    # print 'k_idxs', k_idxs, terminals\n",
    "\n",
    "    i_idxs = [model.vocab_i[x] for x in ancestors]\n",
    "    i_idxs += [0] * (model.memsize_i - len(i_idxs))  # padding\n",
    "    # print 'i_idxs', i_idxs, ancestors\n",
    "\n",
    "    r_pos_idx, r_neg_idxs = bimodal.find_r_idxs_train(\n",
    "        model, parent, children)\n",
    "    # print 'r_pos_idx', r_pos_idx\n",
    "    # print 'r_neg_idxs', r_neg_idxs\n",
    "\n",
    "    # print 'parent', parent\n",
    "    # print 'children', children\n",
    "\n",
    "    return i_idxs, k_idxs, l_idxs, r_pos_idx, r_neg_idxs\n",
    "\n",
    "iklr1 = prepare_iklr(utter, ptree1)\n",
    "iklr2 = prepare_iklr(utter, ptree2)\n",
    "def train_and_swap():\n",
    "    global next_ptree\n",
    "    next_ptree = ptree2 if next_ptree == ptree1 else ptree1\n",
    "    label = 'TRAINING X' if next_ptree == ptree2 else 'TRAINING F'\n",
    "    terminals, ancestors, parent, children = next_ptree\n",
    "    weights_before4 = show_weights(model, iklr1[0], iklr1[1], iklr1[2], [4,5])\n",
    "    weights_before5 = show_weights(model, iklr2[0], iklr2[1], iklr2[2], [4,5])\n",
    "    \n",
    "    i_idxs, k_idxs, l_idxs, r_pos_idx, r_neg_idxs = \\\n",
    "        prepare_iklr(utter, next_ptree)\n",
    "    print r_pos_idx, r_neg_idxs[0]\n",
    "    bimodal.train_a_pair(model, i_idxs, k_idxs, l_idxs, \n",
    "                         r_pos_idx, r_neg_idxs, model.alpha)\n",
    "    weights_after4 = show_weights(model, iklr1[0], iklr1[1], iklr1[2], [4,5])\n",
    "    weights_after5 = show_weights(model, iklr2[0], iklr2[1], iklr2[2], [4,5])\n",
    "\n",
    "    positions = np.array([1,2,4,5,8,9,11,12])\n",
    "    plt.bar(positions,\n",
    "            np.concatenate(\n",
    "            (weights_before4,weights_before5,\n",
    "             weights_after4,weights_after5)))\n",
    "    plt.xticks(positions+0.5, ['FF','FX','XF','XX']*2)\n",
    "    plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEKCAYAAADticXcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEekRFXURkR5RURcR6ZH/By57hqHBJeFTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d9f1810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_and_swap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_idxs, k_idxs, l_idxs, r_pos_idx, r_neg_idxs = iklr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_idxs, k_idxs, l_idxs, r_pos_idx, r_neg_idxs = iklr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmati\n",
      "[[ 0.49609876  0.29516587  0.4892112   0.43958676]\n",
      " [ 0.49988252  2.37215805  0.53028822  0.77694088]]\n",
      "hmatk\n",
      "[[ 0.50026083  1.03371394  0.5140211   0.80243039]\n",
      " [ 0.50128168  0.2684443   0.48784003  0.43515486]]\n"
     ]
    }
   ],
   "source": [
    "hmati = model.hmati  # memsize_i * vector_size\n",
    "hmatk = model.hmatk  # memsize_k * vector_size\n",
    "i_vecs = model.syn0i[i_idxs]  # memsize_i * vector_size\n",
    "k_vecs = model.syn0k[k_idxs]  # memsize_k * vector_size\n",
    "l_vecs = model.syn0l[l_idxs]  # arbitrary * vector_size\n",
    "print 'hmati'\n",
    "print hmati\n",
    "print 'hmatk'\n",
    "print hmatk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c [  5.53919040e-02  -4.62169409e+00   1.28126517e-03  -4.76013452e-01]\n",
      "h [ 0.01018697 -4.76790237 -0.07225341 -0.53727841]\n"
     ]
    }
   ],
   "source": [
    "c = np_mult(i_vecs, hmati).sum(0) + \\\n",
    "    np_mult(k_vecs, hmatk).sum(0)  # 1 * vector_size\n",
    "l = l_vecs.mean(0)  # 1 * vector_size\n",
    "\n",
    "assert model.additive\n",
    "h = c + l  # 1 * vector_size\n",
    "\n",
    "print 'c', c\n",
    "print 'h', h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_vecs\n",
      "[[ 0.06446565 -1.58717561  0.05181413 -0.39819199]\n",
      " [ 0.05000554  1.58362257  0.20109867  0.48790494]]\n",
      "b\n",
      "[ 0.00802556 -0.02759348]\n"
     ]
    }
   ],
   "source": [
    "r_indices = [r_pos_idx] + r_neg_idxs\n",
    "r_vecs = model.syn1r[r_indices]  # (1 + negative) * vector_size\n",
    "b = model.syn1b[r_indices]  # 1 * (1 + negative)\n",
    "print 'r_vecs'\n",
    "print r_vecs\n",
    "print 'b'\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f [  9.99588907e-01   3.84326704e-04]\n"
     ]
    }
   ],
   "source": [
    "f = 1. / (1. + exp(- dot(h, r_vecs.T) - b))  # 1 * (1 + negative)\n",
    "print 'f', f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights\n",
      "[ 7.79635096 -7.86363316]\n",
      "exp(weights)\n",
      "[  2.43171240e+03   3.84474464e-04]\n"
     ]
    }
   ],
   "source": [
    "print 'weights'\n",
    "print dot(h, r_vecs.T) + b\n",
    "print ('exp(weights)')\n",
    "print exp(dot(h, r_vecs.T) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g [ 0.00041515 -0.00038792]\n",
      "alpha 1.0\n"
     ]
    }
   ],
   "source": [
    "g = (model.neg_labels[:len(r_indices)] - f) * model.alpha  # 1 * (1 + negative)\n",
    "print 'g', g\n",
    "print 'alpha', model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EH [  7.36432577e-06  -1.27323550e-03  -5.65005694e-05  -3.54578026e-04]\n"
     ]
    }
   ],
   "source": [
    "neu1e = dot(g, r_vecs)  # 1 * vector_size\n",
    "print 'EH', neu1e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer(g,h)\n",
      "[[  4.22908197e-06  -1.97937727e-03  -2.99957379e-05  -2.23049173e-04]\n",
      " [ -3.95176964e-06   1.84958416e-03   2.80288363e-05   2.08423236e-04]]\n"
     ]
    }
   ],
   "source": [
    "print 'outer(g,h)'\n",
    "print outer(g,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n",
      "[ 0.00844071 -0.02798141]\n"
     ]
    }
   ],
   "source": [
    "model.syn1b[r_indices] += g\n",
    "\n",
    "b = model.syn1b[r_indices]  # 1 * (1 + negative)\n",
    "print 'b'\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_vecs\n",
      "[[ 0.06446988 -1.58915496  0.05178413 -0.39841503]\n",
      " [ 0.05000159  1.58547211  0.20112669  0.48811337]]\n"
     ]
    }
   ],
   "source": [
    "model.syn1r[r_indices] += outer(g, h)\n",
    "r_vecs = model.syn1r[r_indices]  # (1 + negative) * vector_size\n",
    "print 'r_vecs'\n",
    "print r_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert model.additive\n",
    "neu1e_c = neu1e\n",
    "neu1e_l = neu1e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.syn0i[i_idxs] += np_mult(hmati, neu1e_c)\n",
    "model.syn0k[k_idxs] += np_mult(hmatk, neu1e_c)\n",
    "model.hmati += np_mult(i_vecs, neu1e_c)\n",
    "model.hmatk += np_mult(k_vecs, neu1e_c)\n",
    "model.syn0l[l_idxs] += neu1e_l / len(l_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- Initialization matters\n",
    "  - when I change the initialization of `hmati` and `hmatk` and `syn1b` to the way dictated by the paper, I was able to make the training process coverge to a desired state.\n",
    "    - Actually, only the change of the initializations of `hmati` and `hmatk` is necessary.\n",
    "    - Anyway, the changes have been adapted to the current implementation now.\n",
    "- Learning rate matters\n",
    "  - setting `alpha` to 1 works great.\n",
    "  - 0.25 works fine\n",
    "  - setting `alpha` to 0.025 (gensim's default learning rate) doesn't.\n",
    "- Overflow in np.exp and np.multiply are dangerous.\n",
    "  - The `exp(h.dot(r_vecs.T))` value goes up and up and won't stop. Do something about it??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Test NL-PL Matching\n",
    "\n",
    "Do not need the above code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 One-to-one mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bimodal:under 10 jobs per worker: consider setting a smaller `batch_ptrees' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utter=f, code=f(x)\n",
      "utter=g, code=g(x)\n",
      "utter=h, code=h(x)\n",
      "utter=r, code=r(x)\n",
      "utter=t, code=t(x)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../models/')\n",
    "import bimodal\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import ast\n",
    "import astunparse\n",
    "import myast\n",
    "\n",
    "from numpy import multiply as np_mult, exp, dot, outer\n",
    "\n",
    "MEMSIZE = 10\n",
    "\n",
    "codes = [\"f(x)\", \"g(x)\", \"h(x)\", \"r(x)\", \"t(x)\"]\n",
    "utters = ['f', 'g', 'h', 'r', 't']\n",
    "nodes = [ast.parse(x) for x in codes]\n",
    "myasts = [myast.MyAST(node=x) for x in nodes]\n",
    "train_pairs = zip(utters, myasts)\n",
    "\n",
    "reload(bimodal);\n",
    "\n",
    "model = bimodal.BiModal(\n",
    "    train_pairs = train_pairs,\n",
    "    size = 20,\n",
    "    min_count = None,\n",
    "    workers = 1,\n",
    "    iter_ = 100,\n",
    "    null_word = False,\n",
    "    sample = None,\n",
    "    additive = True,\n",
    "    memsize_k = MEMSIZE,\n",
    "    memsize_i = MEMSIZE,\n",
    "    alpha = 0.25,  # CAUTION!!!!!!!!!!!!\n",
    "    seed = 1,\n",
    "    train_on_init=True)\n",
    "\n",
    "for utter in utters:\n",
    "    my_callback = model.getSampleCallback(utter)\n",
    "    myast_sampled = myast.MyAST.sample_from_root(\n",
    "        memsize_k=MEMSIZE, memsize_i=MEMSIZE, callback=my_callback)\n",
    "\n",
    "    code_sampled = astunparse.unparse(myast_sampled.node)\n",
    "    print 'utter=%s, code=%s'%(utter, code_sampled.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Many-to-one Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bimodal:under 10 jobs per worker: consider setting a smaller `batch_ptrees' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utter=f1, code=f(x)\n",
      "utter=g1, code=g(x)\n",
      "utter=h1, code=h(x)\n",
      "utter=r1, code=r(x)\n",
      "utter=t1, code=t(x)\n",
      "utter=f2, code=f(x)\n",
      "utter=g2, code=g(x)\n",
      "utter=h2, code=h(x)\n",
      "utter=r2, code=r(x)\n",
      "utter=t2, code=t(x)\n",
      "utter=f3, code=f(x)\n",
      "utter=g3, code=g(x)\n",
      "utter=h3, code=h(x)\n",
      "utter=r3, code=r(x)\n",
      "utter=t3, code=t(x)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../models/')\n",
    "import bimodal\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import ast\n",
    "import astunparse\n",
    "import myast\n",
    "\n",
    "from numpy import multiply as np_mult, exp, dot, outer\n",
    "\n",
    "MEMSIZE = 10\n",
    "\n",
    "codes = [\"f(x)\", \"g(x)\", \"h(x)\", \"r(x)\", \"t(x)\"]\n",
    "utters = ['f', 'g', 'h', 'r', 't']\n",
    "utters1 = [x+'1' for x in utters]\n",
    "utters2 = [x+'2' for x in utters]\n",
    "utters3 = [x+'3' for x in utters]\n",
    "nodes = [ast.parse(x) for x in codes]\n",
    "myasts = [myast.MyAST(node=x) for x in nodes]\n",
    "train_pairs = zip(utters1, myasts) + zip(utters2, myasts) + zip(utters3, myasts)\n",
    "\n",
    "reload(bimodal);\n",
    "\n",
    "model = bimodal.BiModal(\n",
    "    train_pairs = train_pairs,\n",
    "    size = 20,\n",
    "    min_count = None,\n",
    "    workers = 1,\n",
    "    iter_ = 100,\n",
    "    null_word = False,\n",
    "    sample = None,\n",
    "    additive = True,\n",
    "    memsize_k = MEMSIZE,\n",
    "    memsize_i = MEMSIZE,\n",
    "    alpha = 0.25,  # CAUTION!!!!!!!!!!!!\n",
    "    seed = 1,\n",
    "    train_on_init=True)\n",
    "\n",
    "for utter, _ in train_pairs:\n",
    "    my_callback = model.getSampleCallback(utter)\n",
    "    myast_sampled = myast.MyAST.sample_from_root(\n",
    "        memsize_k=MEMSIZE, memsize_i=MEMSIZE, callback=my_callback)\n",
    "\n",
    "    code_sampled = astunparse.unparse(myast_sampled.node)\n",
    "    print 'utter=%s, code=%s'%(utter, code_sampled.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Unseen Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bimodal:under 10 jobs per worker: consider setting a smaller `batch_ptrees' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utter=f1, code=f(x)\n",
      "utter=g1, code=g(x)\n",
      "utter=h1, code=h(x)\n",
      "utter=r1, code=r(x)\n",
      "utter=t1, code=t(x)\n",
      "utter=f2, code=f(x)\n",
      "utter=g2, code=g(x)\n",
      "utter=h2, code=h(x)\n",
      "utter=r2, code=r(x)\n",
      "utter=t2, code=t(x)\n",
      "utter=f3, code=f(x)\n",
      "utter=g3, code=g(x)\n",
      "utter=h3, code=h(x)\n",
      "utter=r3, code=r(x)\n",
      "utter=t3, code=t(x)\n",
      "utter=f1 Unknown Word, code=f(x)\n",
      "utter=xxx, code=f(x)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../models/')\n",
    "import bimodal\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import ast\n",
    "import astunparse\n",
    "import myast\n",
    "\n",
    "from numpy import multiply as np_mult, exp, dot, outer\n",
    "\n",
    "MEMSIZE = 10\n",
    "\n",
    "codes = [\"f(x)\", \"g(x)\", \"h(x)\", \"r(x)\", \"t(x)\"]\n",
    "utters = ['f', 'g', 'h', 'r', 't']\n",
    "utters1 = [x+'1' for x in utters]\n",
    "utters2 = [x+'2' for x in utters]\n",
    "utters3 = [x+'3' for x in utters]\n",
    "nodes = [ast.parse(x) for x in codes]\n",
    "myasts = [myast.MyAST(node=x) for x in nodes]\n",
    "train_pairs = zip(utters1, myasts) + zip(utters2, myasts) + zip(utters3, myasts)\n",
    "\n",
    "reload(bimodal);\n",
    "\n",
    "model = bimodal.BiModal(\n",
    "    train_pairs = train_pairs,\n",
    "    size = 20,\n",
    "    min_count = None,\n",
    "    workers = 1,\n",
    "    iter_ = 100,\n",
    "    null_word = True,  # <-- this is changed!!\n",
    "    sample = None,\n",
    "    additive = True,\n",
    "    memsize_k = MEMSIZE,\n",
    "    memsize_i = MEMSIZE,\n",
    "    alpha = 0.25,  # CAUTION!!!!!!!!!!!!\n",
    "    seed = 1,\n",
    "    train_on_init=True)\n",
    "\n",
    "utters_trained = [x[0] for x in train_pairs]\n",
    "for utter in utters_trained + ['f1 Unknown Word', 'xxx']:\n",
    "    my_callback = model.getSampleCallback(utter)\n",
    "    myast_sampled = myast.MyAST.sample_from_root(\n",
    "        memsize_k=MEMSIZE, memsize_i=MEMSIZE, callback=my_callback)\n",
    "\n",
    "    code_sampled = astunparse.unparse(myast_sampled.node)\n",
    "    print 'utter=%s, code=%s'%(utter, code_sampled.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
